# -*- coding: utf-8 -*-
"""B21CS091_LAB_Assignment_6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a6ZBfp7nQiQGBmf1vc_aKfacC1-vhYLV

Question 1
"""

import numpy as np
import pandas as pd

data = pd.read_csv('/content/glass.csv')

data.head()

print(data.isna().sum())

#found no NULL values

import matplotlib.pyplot as plt

data.hist(figsize=[12, 10])
plt.show()

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X = np.array(data.drop(['Type'], axis = 1).copy())
Y = np.array(data['Type'])

X = scaler.fit_transform(X)


labels = np.unique(Y).shape[0]

print(labels)
print(X.shape)
print(Y.shape)

from sklearn.cluster import KMeans

fig, ax = plt.subplots(1, labels, figsize = (20,8))

for lb in range(labels):
    KM = KMeans(n_clusters=lb+1).fit(X)
    centroids = KM.cluster_centers_

    ax[lb].scatter(X[:, 2], X[:, 3], c = KM.labels_, s = 10)
    ax[lb].set_title("Clusters = "+str(lb+1))
    ax[lb].scatter(centroids[:,2] , centroids[:,3] , s = 100, color = 'k')

from sklearn.metrics import silhouette_score


for lb in range(1, labels):
    KM = KMeans(n_clusters=lb+1).fit(X)
    pred = KM.predict(X).reshape(-1, 1)

    print("Silhouette_score for {} Clusters is {}".format(lb+1, silhouette_score(pred, Y)))

K_values = range(1, 30)

inertias = []
for i in K_values:
    KM = KMeans(n_clusters=i)
    KM.fit(X)
    inertias.append(KM.inertia_)

f = plt.figure()
f.set_figwidth(10)
f.set_figheight(5)
plt.plot(K_values, inertias, 'bx-')

plt.xlabel('Number of Estimators')
plt.ylabel('WCSS Value')
plt.title('Elbow Method')
plt.grid()
plt.show()

from sklearn.ensemble import BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier as KNN
from sklearn.metrics import accuracy_score

BC = BaggingClassifier(estimator=KNN(n_neighbors = 3), n_estimators=10)

KNN_=  KNN(n_neighbors = 4)
KNN_.fit(X, Y)
Y_pred_knn = KNN_.predict(X) 

BC.fit(X, Y)
Y_pred = BC.predict(X)


print("Accuracy with Bagging with KNN classifier :", accuracy_score(Y_pred, Y))

print("Accuracy (without Bagging) of KNN classifier :", accuracy_score(Y_pred_knn, Y))
# print(Y)





"""Question 2"""

import random
import matplotlib.pyplot as plt


class KMeans:
    def __init__(self, n_clusters):
        self.K = n_clusters
        self.max_iterations = 100
        self.centroids = []
        self.clusters = [[]]*n_clusters

    def fit(self, X, indexes=  None):
        rows = X.shape[0]
        columns = X.shape[1]
        
        if indexes == None:
            self.centroids = np.zeros((self.K, columns))

            for i in range(self.K):
                self.centroids[i] = X[random.randrange(rows)]
        else:
            self.centroids = X[indexes]

        for i in range(self.max_iterations):

            self.clusters = [[] for _ in range(self.K)]
            for index in range(rows):

                dists = np.sqrt(np.sum((self.centroids-X[index])**2, axis = 1))

                self.clusters[np.argmin(dists)].append(index)
 
            
            new_centroids = np.zeros((self.K, columns))

            for idx in range(self.K):
                new_centroids[idx] = np.mean(X[self.clusters[idx]], axis=0)

            if not (self.centroids - new_centroids).any():
                break
            
            self.centroids = new_centroids.copy()

            for i in range(self.K):
                if len(self.clusters[i]) == 0:
                    self.centroids[i] = X[random.randrange(rows)]

        
    def predict(self, X):

        y_pred = np.zeros(X.shape[0]) 

        for i in range(self.K):
            y_pred[self.clusters[i]] = i
        return y_pred

    def plot_centroids(self):
        fig, ax = plt.subplots(self.K//10, 10, figsize = (20, 8))

        for i, ax_ in enumerate(ax.flat):
            ax_.imshow(KM.centroids[i].reshape(64, 64), cmap='gray')

import sklearn.datasets as dt

data = dt.fetch_olivetti_faces(data_home=None, shuffle=False, random_state=0, download_if_missing=True)

X = data['data']
Y = data['target']

print(X.shape)
print(Y.shape, '\n')
print(X[0:5])

idx = random.sample(range(0, 400), 40)

KM = KMeans(n_clusters = 40)
KM.fit(X, idx)


Y_pred = KM.predict(X)


for i in range(40):
    print("{} -> {}".format(i, np.count_nonzero(Y_pred == i)))

KM.plot_centroids()

cls = KM.clusters
import matplotlib.pyplot as plt

fig, ax = plt.subplots(40, 10, figsize = (15, 100))
for i in range(40):
    for j in range(10):
        if j < len(cls[i]):
            ax[i, j].imshow(X[cls[i][j]].reshape(64, 64), cmap='gray')

import matplotlib.pyplot as plt

idx = random.sample(range(0, 400), 10)

KM2 = KMeans(n_clusters = 10)
KM2.fit(X, idx)

Y_pred2 = KM2.predict(X)

for i in range(10):
    print("{} -> {}".format(i, np.count_nonzero(Y_pred2 == i)))
KM2.plot_centroids()

cls = KM2.clusters

fig, ax = plt.subplots(10, 10, figsize = (15, 25))
for i in range(10):
    for j in range(10):
        if j < len(cls[i]):
            ax[i, j].imshow(X[cls[i][j]].reshape(64, 64), cmap='gray')

def SSE(true, pred):
    sse = 0.0
    for i in range(len(true)):
        error = true[i] - pred[i]
        sse += error**2
    return sse

print("The Sum of Squared Error for Part c is :", SSE(Y_pred, Y))
print("The Sum of Squared Error for Part f is :", SSE(Y_pred2, Y))



"""Question 3"""

import numpy as np
import pandas as pd

data = pd.read_csv('/content/Wholesale customers data.csv')

data.head()

print(data.isna().sum())

data.hist(figsize = (15, 10))

from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA

X = data.drop(['Channel'], axis = 1).copy()
Y = data['Channel']

PC = PCA(n_components = 2)
X_sc = PC.fit_transform(X)

MMS = MinMaxScaler()

X = MMS.fit_transform(X)

print(X[0:5])

import matplotlib.pyplot as plt

COV = np.cov(X.T)

max = COV[0, 1]
ans = [0, 1]


for i in range(len(COV)):
    for j in range(i+1, len(COV)):
        if(COV[i, j] > max):
            max = COV[i, j]
            ans = [i, j]
    

print("The features with maximum Covariance are {} and {}\n".format(ans[0], ans[1]))


plt.scatter(X[:, ans[0]], X[:, ans[1]], s = 6)
plt.show()

from sklearn.cluster import DBSCAN

DBS = DBSCAN().fit(X)

Y = DBS.labels_

f = plt.figure()
f.set_figwidth(15)
f.set_figheight(8)
plt.scatter(X_sc[:, 0], X_sc[:, 1], c = Y, s = 15)
plt.show()

from sklearn.cluster import KMeans

KM = KMeans()

KM.fit(X)
Y_KM = KM.predict(X)

f = plt.figure()
f.set_figwidth(15)
f.set_figheight(8)
plt.scatter(X_sc[:, 0], X_sc[:, 1], c = Y_KM, s = 15)

plt.show()

from sklearn.datasets import make_moons

data = make_moons(n_samples = 2000, noise = 0.1)
X = data[0]
Y = data[1]

for i in range(400):
    idx = np.random.randint(0, X.shape[0])
    X = np.vstack([X, np.random.normal(X[idx], 0.05)])
    Y = np.append(Y, Y[idx])

from sklearn.cluster import DBSCAN

DBS = DBSCAN(eps = 0.1, min_samples=20)
dbscan_labels = DBS.fit_predict(X)

KM_def = KMeans()

KM = KMeans(n_clusters = 2)
KM_def
KM_labels = KM.fit(X).predict(X)


plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.scatter(X[:, 0], X[:, 1], c=Y, cmap='viridis', s=10)
plt.title('Original Data')
plt.subplot(1, 3, 2)
plt.scatter(X[:, 0], X[:, 1], c=dbscan_labels, cmap='viridis', s=10)
plt.title('DBSCAN ')
plt.subplot(1, 3, 3)
plt.scatter(X[:, 0], X[:, 1], c=KM_labels, cmap='viridis', s=10)
plt.title('KMeans Classifier')





